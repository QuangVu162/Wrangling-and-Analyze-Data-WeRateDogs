{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reporting: wragle_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To wrangle WeRateDogs Twitter data to create interesting and trustworthy analyses and visualizations. The Twitter archive is great, but it only contains very basic tweet information. Additional gathering, then assessing and cleaning is required for \"Wow!\"-worthy analyses and visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enhanced Twitter Archive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The WeRateDogs Twitter archive contains basic tweet data for all 5000+ of their tweets, but not everything. One column the archive does contain though: each tweet's text, which I used to extract rating, dog name, and dog \"stage\" (i.e. doggo, floofer, pupper, and puppo) to make this Twitter archive \"enhanced.\" Of the 5000+ tweets, I have filtered for tweets with ratings only (there are 2356). The dataset is provided so that it could be downloaded and then imported into the the Dataframe called \"twit_df\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image Predictions File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a table full of image predictions (the top three only) alongside each tweet ID, image URL, and the image number that corresponded to the most confident prediction which is filed and provided by Udacity. \n",
    "\n",
    "This file (image_predictions.tsv) is present in each tweet according to a neural network. It is hosted on Udacity's servers and should be downloaded programmatically using the Requests library and the following URL: https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv\n",
    "\n",
    "The file is then imported into the Dataframe named \"img_df\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additional Data via the Twitter API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to the basic-ness of Twitter archives: retweet count and favorite count are two of the notable column omissions. Fortunately, this additional data can be gathered by anyone from Twitter's API. \n",
    "\n",
    "Using the Twitter's ID provided by the Twitter and the Tweepy library, we have crawled the data for the WeRateDogs and store under the JSON format. The dataset is then imported into the Dataframe named \"api_df\" and only contain the information of tweet_id, favorite_count and retweet_count.\n",
    "\n",
    "However, due to the difficulty in the requirements from Twitter to acquire the accessment to the data, within the scope of this project, we used the data provided under csv format and imported directly to the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quality issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. tweet_id should be in string type, note int64 \n",
    "\n",
    "2. \"timestamp\" column is string type, not timestamps type\n",
    "\n",
    "3. There are some values which could be considered as not appropriate in the \"name\" column: 'a', 'quite', 'not', 'one', 'an', 'mad', 'very,' just', 'my', 'his', 'actually', 'getting', 'this', 'unacceptable', 'all', 'old', 'the', 'by', 'life', 'light', 'space'\n",
    "\n",
    "4. Rating_numerator should be converted into float64, instead of int64 due to there are decimal number in the text and the current data type could not capture it.\n",
    "\n",
    "5. We only consider the original tweet and eliminate all rows which are retweet and reply\n",
    "\n",
    "6. We would choose rows that have images identified by joining with image-predictions dataframe\n",
    "\n",
    "7. There are not appropriate values in the rating_denomination which should always equal to 10. The rating_numerator also encouter the same issue, however, we believe after the fix of the rating_denomination column, the data issue of rating_numerator column would be eliminated accordingly.\n",
    "\n",
    "8. There are 5 columns having majorly \"NaN\" value in twitter_archive_enhanced dataset. As such, they could be dropped off due to their current position in the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tidiness issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The columns contain the information of the stages of dog life (i.e. doggo, floofer, pupper, puppo) in the twitter_archive_enhanced dataset should not be seperated into three columns as it shows many \"None\" values in these 3 columns. Accordingly, these columns should be combined into only one column.\n",
    "\n",
    "2. The \"source\" column should be seperated into two columns: \"url\" and \"device\", because one column source is containing two information for two independent variables."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
